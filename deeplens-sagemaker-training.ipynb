{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLens Outware faces training\n",
    "\n",
    "This is an end to end template of how to train a image classification model and inference with it in Amazon SageMaker. Please make a copy and modify from there, if you want to train your own model. \n",
    "\n",
    "In this template, we use the faces extracted from outware photos as training data. Check `deeplens_sagemaker_data_preparation.ipynb` notebook for how to prepare data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "### Initial configuration\n",
    "\n",
    "Setup for SageMaker jobs, we are using image classification image provided by Amazon.\n",
    "\n",
    "Please modify the *bucket* and *train_name* to match your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# Customize to your S3 bucket\n",
    "bucket='deeplens-sagemaker-2bbe16b4-c056-4ae2-9332-d31dd7aeb470'\n",
    "train_name='gender'\n",
    "\n",
    "# Training image container\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "See the detailed explanation of each hyperparameters in [here](https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html)\n",
    "\n",
    "You will need modify these hyper parameters to match your training data and requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pre-trained model to populate parameters\n",
    "use_pretrained_model = \"1\"\n",
    "# Checkpoint frequency, for example, for checkpoint_frequency = \"10\", the training job will save the model artifact every 10 epochs\n",
    "checkpoint_frequency = \"5\"\n",
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = \"50\" \n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,224,224\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "# num_training_samples is the number of line in our YOUR_DATA_PREFIX_train.lst file\n",
    "num_training_samples = \"1294\"\n",
    "# specify the number of output classes\n",
    "# num_classes is the number of lines in our outwarians_labels file\n",
    "num_classes = \"2\"\n",
    "# batch size for training\n",
    "# make sure it is not too big \n",
    "mini_batch_size = \"32\"\n",
    "# number of epochs\n",
    "epochs = \"100\"\n",
    "# optimizer\n",
    "optimizer = \"sgd\"\n",
    "# learning rate\n",
    "learning_rate = \"0.1\"\n",
    "# Decrease factor for learning rate\n",
    "lr_scheduler_factor = \"0.1\"\n",
    "# Epoch number when decrease in learning rate should happen, comma separated\n",
    "lr_scheduler_step = \"80,90\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters\n",
    "\n",
    "In this section, we setup training parameters. Note that you will need two input channels for image classification they are our train and validation folders on the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "# create unique job name \n",
    "job_name_prefix = 'sagemaker-{}-training-notebook'.format(train_name)\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/model/{}/{}/output'.format(bucket, train_name, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.xlarge\",\n",
    "        \"VolumeSizeInGB\": 100\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"use_pretrained_model\": str(use_pretrained_model),\n",
    "        \"checkpoint_frequency\": str(checkpoint_frequency),\n",
    "        \"optimizer\": str(optimizer),\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate),\n",
    "        \"lr_scheduler_factor\": str(lr_scheduler_factor),\n",
    "        \"lr_scheduler_step\": str(lr_scheduler_step),\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 43200\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"validation\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/train/{}/'.format(bucket, train_name),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/validation/{}/'.format(bucket, train_name),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nTraining Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))\n",
    "print('\\nValidation Data Location: {}'.format(training_params['InputDataConfig'][1]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model\n",
    "\n",
    "Create a training model job with the parameter we set in the earlier step. It will kick off an EC2 node we specified above as \"ml.m4.xlarge\", it has 4 vCPU, NVidia K80 Graphics card with 12GB GPU ram, 61GB of system ram and 100GB of EBS, also this instance cost $0.90/hr/node.\n",
    "\n",
    "Once the training job has started you can go to [Console > SageMaker > Jobs](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs) to check the latest job progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus'] + \": \" + training_info[\"SecondaryStatus\"]\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus'] + \": \" + training_info[\"SecondaryStatus\"]\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sagemaker = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"test-{}-classification-model{}\".format(train_name, timestamp)\n",
    "print(model_name)\n",
    "info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "hosting_image = containers[boto3.Session().region_name]\n",
    "primary_container = {\n",
    "    'Image': hosting_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sagemaker.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint\n",
    "\n",
    "The endpoint is also hosted on ml.m4.xlarge, it will incur same cost as our training job. Please delete the endpoint after you finish all the work. Endpoint can always be recreated from the endpoint configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n",
    "\n",
    "\n",
    "# wait until the status has changed\n",
    "sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "print('Endpoint creation ended with EndpointStatus = {}'.format(status))\n",
    "\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "In this section we will test our model with a set of images on the S3 bucket.\n",
    "\n",
    "Update the following environment variable for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TRAIN_LABEL=om_gender_label\n",
    "%env TEST_IMAGE_PATH=test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Download test images\"\n",
    "aws s3 cp --recursive \"s3://deeplens-sagemaker-2bbe16b4-c056-4ae2-9332-d31dd7aeb470/$TEST_IMAGE_PATH/\" ./$TEST_IMAGE_PATH/\n",
    "echo \"Download label file\"\n",
    "aws s3 cp \"s3://deeplens-sagemaker-2bbe16b4-c056-4ae2-9332-d31dd7aeb470/$TRAIN_LABEL\" .\n",
    "echo \"Download cv2 face detection model\"\n",
    "aws s3 cp \"s3://deeplens-sagemaker-2bbe16b4-c056-4ae2-9332-d31dd7aeb470/model/opencv_haarcascade_model/haarcascade_frontalface_default.xml\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "label_file_name = os.environ['TRAIN_LABEL']\n",
    "test_image_path = os.environ['TEST_IMAGE_PATH']\n",
    "print(label_file_name)\n",
    "print(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "labels = []\n",
    "\n",
    "\n",
    "def loadLabel():\n",
    "    with open(label_file_name) as f:\n",
    "        for line in f:\n",
    "            (label, index) = line.split()\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "def findFaces(imageNdarray, classifier):\n",
    "    faces = classifier.detectMultiScale(imageNdarray,\n",
    "                                        scaleFactor=1.3,\n",
    "                                        minNeighbors=5,\n",
    "                                        minSize=(50, 50),\n",
    "                                        flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (x, y, w, h) in faces:\n",
    "        yield (x, y , w, h)\n",
    "\n",
    "\n",
    "def queryEndpoint(face):\n",
    "    face = cv2.resize(face, (224, 224), interpolation = cv2.INTER_CUBIC)\n",
    "    ret, face = cv2.imencode('.jpg', face)\n",
    "    if ret == True:\n",
    "        face = bytearray(face.tostring())\n",
    "    else:\n",
    "        print('Failed to prepare image for recognition')\n",
    "        return\n",
    "\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                       ContentType='application/x-image', \n",
    "                                       Body=face)\n",
    "    result = response['Body'].read()\n",
    "    # result will be in json format and convert it to ndarray\n",
    "    result = json.loads(result)\n",
    "    # the result will output the probabilities for all classes\n",
    "    # find the class with maximum probability and print the class index\n",
    "    index = np.argmax(result)\n",
    "    prob = result[index]\n",
    "    thresh = 0.50\n",
    "    if prob < thresh:\n",
    "        print(\"Result: Highest probility below threshold ({:.2f}%).\".format(thresh * 100))\n",
    "    else:\n",
    "        print(\"Result: label - {}, probability - {:.2f}%\".format(labels[index], result[index] * 100))\n",
    "\n",
    "    for i in range(0, len(result)):\n",
    "        print(\"    Label - {}, probability - {:.2f}%\".format(labels[i], result[i] * 100))\n",
    "\n",
    "\n",
    "\n",
    "def checkFace(fileName, faceCascade):\n",
    "    image = cv2.imread(fileName, 1)\n",
    "    faces = findFaces(image, faceCascade)\n",
    "    for face in faces:\n",
    "        (x, y, w, h) = face\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        queryEndpoint(face)\n",
    "\n",
    "\n",
    "photos = glob(\"./{}/*.jpg\".format(test_image_path))\n",
    "\n",
    "loadLabel()\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "\n",
    "for photo in photos:\n",
    "    print(photo)\n",
    "    checkFace(photo, faceCascade)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Remove test artifacts\"\n",
    "rm ./$TRAIN_LABEL\n",
    "rm -rf ./$TEST_IMAGE_PATH/\n",
    "rm ./haarcascade_frontalface_default.xml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
